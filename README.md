# ğŸ•µğŸ»â€â™‚ï¸ DLA DEEPFAKE DETECTION 2024/25 - UNICA  
**Deepfake Detection Project using the OpenForensics dataset**  

## ğŸ§‘ğŸ»â€ğŸ“ Students  
#### Francesco Congiu  
> Student ID: 60/73/65300  
>  
>> E-Mail: f.congiu38@studenti.unica.it  

#### Simone Giuffrida  
> Student ID: 60/73/65301  
>  
>> E-Mail: s.giuffrida2@studenti.unica.it  

#### Fabio Littera  
> Student ID: 60/73/65310  
>  
>> E-Mail: f.littera3@studenti.unica.it  

---

## ğŸ“Œ Description  
This repository contains the code for training and evaluating deepfake detection models using the **OpenForensics** dataset. The project follows two approaches:  
1. **Transfer Learning** with pre-trained models (e.g., MobileNet, Xception).  
2. **Training from Scratch** with a custom neural network.  

---

## ğŸ“¥ Download the Dataset  
The **OpenForensics** dataset required for the project can be downloaded from the following link:  
ğŸ”— **[OpenForensics Dataset - Zenodo](https://zenodo.org/records/5528418)**  

---

## ğŸ“„ **Documentation**  
Below are links to the full project documentation:
- ğŸ“š [Theoretical Background](documentation/BACKGROUND.md)
- ğŸ›  [Feature Extraction](documentation/FEATURE_EXTRACTION.md)
- ğŸ“Š [Metadata Analysis](documentation/METADATA_ANALYSIS.md)
- ğŸ¯ [Fine Tuning of MobileNet and xCeption](documentation/FINE_TUNING.md)
- ğŸ— [Building a Network from the Ground Up](documentation/CUSTOM_NETWORK.md)

ğŸ“‚ **[Cartella con tutta la documentazione](documentation/)**

---

## ğŸš€ Installation  
To run the project locally, follow these steps:

### **1ï¸âƒ£ Clone the Repository**  
Open the terminal and run:
```bash
git clone git@github.com:wakaflocka17/DLA_DEEPFAKEDETECTION.git
cd DLA_DEEPFAKEDETECTION
```
(Or, if using HTTPS)

```bash
git clone https://github.com/wakaflocka17/DLA_DEEPFAKEDETECTION.git
cd DLA_DEEPFAKEDETECTION
```

### **2ï¸âƒ£ Create and Activate a Virtual Environment**
It is recommended to create a virtual environment to isolate dependencies:
```bash
python3 -m venv openforensics_env
source openforensics_env/bin/activate  # macOS/Linux
```
(On Windows, use: `openforensics_env\Scripts\activate`)

### **3ï¸âƒ£ Install Dependencies**
Install all necessary libraries:
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Up the Project Structure**
First, however, we make the script executable with the command:
```bash
chmod +x setup_folders.sh
```
Run the following script to create the required folders:
```bash
setup_folders.sh
```
This will create:
```plaintext
DLA_DEEPFAKEDETECTION/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ Val/
â”‚   â”œâ”€â”€ Test-Dev/
â”‚   â”œâ”€â”€ Test-Challenge/
â”‚   â”œâ”€â”€ dataset/
â”‚
â”‚â”€â”€ processed_data/
â”‚   â”œâ”€â”€ Train/
â”‚   â”‚   â”œâ”€â”€ real/
â”‚   â”‚   â”œâ”€â”€ fake/
â”‚   â”œâ”€â”€ Val/
â”‚   â”‚   â”œâ”€â”€ real/
â”‚   â”‚   â”œâ”€â”€ fake/
â”‚   â”œâ”€â”€ Test-Dev/
â”‚   â”‚   â”œâ”€â”€ real/
â”‚   â”‚   â”œâ”€â”€ fake/
â”‚   â”œâ”€â”€ Test-Challenge/
â”‚   â”‚   â”œâ”€â”€ real/
```

### **5ï¸âƒ£ Download the Dataset**
To automatically download the OpenForensics dataset, use the provided script:
```python
python3 scripts/download_dataset.py
```
ğŸ’¡ Ensure you have a stable internet connection, as the dataset is large (60GB+).

### **6ï¸âƒ£ Move Images and JSON Files to Their Correct Directories**
Now that all files have been extracted, we need to organize them into the correct dataset folders (Train, Val, Test-Dev, Test-Challenge).
Run:
```python
python3 scripts/extract_dataset.py
```
ğŸ’¡ This will:
- Move **training images** to `data/Train/Train/` and the corresponding `Train_poly.json` to `data/Train/`.
- Move **validation images** to `data/Val/Val/` and `Val_poly.json` to `data/Val/`.
- Move **test-dev images** to `data/Test-Dev/Test-Dev/` and `Test-Dev_poly.json` to `data/Test-Dev/`.
- Move **test-challenge images** to `data/Test-Challenge/Test-Challenge/` and `Test-Challenge_poly.json` to `data/Test-Challenge/`.

### **7ï¸âƒ£ Delete Unnecessary ZIP Files**
After extraction and organization, the original .zip files are no longer needed.
Delete them using:
```python
python3 scripts/delete_all_zips.py
```
ğŸ’¡ This will clean up the dataset directory, saving storage space.

### **8ï¸âƒ£ Verify Installation**
To check if everything works correctly, run:
```bash
python3 -c "import torch; print(torch.__version__)"
python3 -c "import cv2; print(cv2.__version__)"
```
If no errors appear, the setup is complete! ğŸ¯

---

## ğŸ› ï¸ Test the DataLoader
Before training, verify that the dataset is correctly loaded:
```python
python3 scripts/dataloader.py --dataset Train --batch_size 32
```
ğŸ’¡ This should display a batch of `images` and `labels`.

## ğŸ”² Evaluate Bounding Boxes
To evaluate the correct extraction of faces by comparing the extracted faces with the bounding boxes provided by the `.json` files within the file, run the following command:
```python
python3 scripts/evaluate_extraction.py 
```
ğŸ’¡ This will:
| **Metric**       | **Threshold**        | **Interpretation** |
|------------------|---------------------|--------------------|
| **Intersection over Union (IoU)** | **IoU** > 0.7 | âœ… **Accurate extraction** |
|                      | 0.5 â‰¤ **IoU** â‰¤ 0.7 | âš ï¸ **Moderate accuracy, possible misalignment** |
|                      | **IoU** < 0.5 | âŒ **Poor extraction, bounding boxes misaligned** |
| **Localization Recall Precision (LRP) Error** | **LRP Error** < 0.2 | âœ… **High localization accuracy** |
|                      | 0.2 â‰¤ **LRP Error** â‰¤ 0.4 | âš ï¸ **Moderate localization errors** |
|                      | **LRP Error** > 0.4 | âŒ **Poor localization, high false positives/negatives** |
| **Average Precision (AP)** | **AP** > 0.8 | âœ… **Highly precise face extraction** |
|                      | 0.5 â‰¤ **AP** â‰¤ 0.8 | âš ï¸ **Moderate accuracy, potential misclassifications** |
|                      | **AP** < 0.5 | âŒ **Unreliable extraction, high error rate** |

This analysis ensures that the face extraction process is aligned with OpenForensics benchmarks before training the model.

## ğŸ¯ Train the Model
Train the model using either `MobileNet` or `Xception`: <br> <br>
âœ… Train with `MobileNet`:
```python
python3 scripts/train.py --model mobilenet
```
âœ… Train with `Xception`:
```python
python3 scripts/train.py --model xception
```
ğŸ’¡ The trained model will be saved in the `models/` directory.

## ğŸ“Š Evaluate the Model
After training, evaluate the model on `Test-Dev` and `Test-Challenge`: <br> <br>
âœ… Evaluate **MobileNet** on `Test-Dev`:
```python
python3 scripts/evaluate.py --model mobilenet --dataset Test-Dev
```
âœ… Evaluate **MobileNet** on `Test-Challenge`:
```python
python3 scripts/evaluate.py --model mobilenet --dataset Test-Challenge
```
âœ… Evaluate **Xception** on `Test-Dev`:
```python
python3 scripts/evaluate.py --model xception --dataset Test-Dev
```
âœ… Evaluate **Xception** on `Test-Challenge`:
```python
python3 scripts/evaluate.py --model xception --dataset Test-Challenge
```
ğŸ’¡ The script will print **Accuracy**, **Precision**, **Recall**, and **F1-score**.

---

## ğŸ“‚ Project Structure  
```plaintext
DLA_DEEPFAKEDETECTION/
â”‚â”€â”€ data/               # Dataset OpenForensics (originale, non modificato)
â”‚   â”œâ”€â”€ Train/          # Training Data
â”‚   â”œâ”€â”€ Val/            # Evaluation Data
â”‚   â”œâ”€â”€ Test-Dev/       # Test-Dev Data
â”‚   â”œâ”€â”€ Test-Challenge/ # Test-Challenge Data
â”‚   â”œâ”€â”€ dataset/        # How to save the original dataset
â”‚
â”‚â”€â”€ processed_data/     # Preprocessing output (cropped faces)
â”‚   â”œâ”€â”€ Train/
â”‚   â”‚   â”œâ”€â”€ real/       # Real faces extracted from the training set
â”‚   â”‚   â”œâ”€â”€ fake/       # Fake faces extracted from the training set
â”‚   â”œâ”€â”€ Val/
â”‚   â”‚   â”œâ”€â”€ real/       # Real faces extracted for evaluation
â”‚   â”‚   â”œâ”€â”€ fake/       # Fake faces extracted for evaluation
â”‚   â”œâ”€â”€ Test-Dev/
â”‚   â”‚   â”œâ”€â”€ real/       # Real faces extracted for Test-Dev
â”‚   â”‚   â”œâ”€â”€ fake/       # Fake faces extracted for Test-Dev
â”‚   â”œâ”€â”€ Test-Challenge/
â”‚   â”‚   â”œâ”€â”€ real/       # Real faces extracted for Test-Challenge
â”‚   â”‚   â”œâ”€â”€ fake/       # Fake faces extracted for Test-Challenge
â”‚
â”‚â”€â”€ documentation/      # Documentation, reports, extra material
â”‚â”€â”€ models/             # Saved models (es. file .pth)
â”‚â”€â”€ scripts/            # Scripts (training, preprocessing, ecc.)
â”‚â”€â”€ notebooks/          # Jupyter Notebook for debugging and testing
â”‚â”€â”€ utils/              # Generic utilities and support functions
â”‚â”€â”€ requirements.txt    # Project dependencies
â”‚â”€â”€ setup_folders.sh    # Script for automatic creation of folders
â”‚â”€â”€ README.md           # Project documentation
```

## ğŸ“Š Project Goals
âœ… **Face extraction** from images using bounding boxes.  
âœ… **Binary classification (fake/real)** of extracted faces.  
âœ… **Training with transfer learning** using MobileNet or Xception.  
âœ… **Development of a custom CNN** for classification.  
âœ… **GPU utilization (MPS on MacBook M4 Pro)** to maximize speed  

---

## ğŸ¤ Contributions  
Feel free to contribute to the project! ğŸ’¡

### ğŸ“Œ How to Contribute
1. Fork the repository.
2. Create a new branch:
   ```bash
   git checkout -b feature-nuova
   ```
3. Commit your changes:
   ```bash
     git commit -m "Aggiunta nuova feature"
   ```
4. Push your changes:
   ```bash
     git push origin feature-nuova
   ```
6. Open a Pull Request on GitHub.



